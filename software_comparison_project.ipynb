{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain image-based meta-analysis with NIDM-Results\n",
    "\n",
    "This notebook demonstrate how to perform a group image-based meta-analysis on the effect of pain using datasets available on [NeuroVault (collection 1425)](http://neurovault.org/collections/1425/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from rdflib.graph import Graph\n",
    "from rdflib.term import URIRef\n",
    "from subprocess import check_call\n",
    "from nidmresults.graph import Graph\n",
    "from nidmresults.objects.constants import SCR_FSL, SCR_SPM\n",
    "import collections\n",
    "import glob\n",
    "import zipfile\n",
    "import json\n",
    "from urllib2 import urlopen, URLError, HTTPError\n",
    "from urllib2 import Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the NIDM-Results packs from NeuroVault\n",
    "\n",
    " - Query NeuroVault's API to retreive all NIDM packs in collection 1425\n",
    " - Download and save the packs in sub-folder `input/data` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://neurovault.org/collections/1425/pain_01.nidm.zip already downloaded at ./input/data/pain/pain_01.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_02.nidm.zip already downloaded at ./input/data/pain/pain_02.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_03.nidm.zip already downloaded at ./input/data/pain/pain_03.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_04.nidm.zip already downloaded at ./input/data/pain/pain_04.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_05.nidm.zip already downloaded at ./input/data/pain/pain_05.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_06.nidm.zip already downloaded at ./input/data/pain/pain_06.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_07.nidm.zip already downloaded at ./input/data/pain/pain_07.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_08.nidm.zip already downloaded at ./input/data/pain/pain_08.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_09.nidm.zip already downloaded at ./input/data/pain/pain_09.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_10.nidm.zip already downloaded at ./input/data/pain/pain_10.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_11.nidm.zip already downloaded at ./input/data/pain/pain_11.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_12.nidm.zip already downloaded at ./input/data/pain/pain_12.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_13.nidm.zip already downloaded at ./input/data/pain/pain_13.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_14.nidm.zip already downloaded at ./input/data/pain/pain_14.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_15.nidm.zip already downloaded at ./input/data/pain/pain_15.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_16.nidm.zip already downloaded at ./input/data/pain/pain_16.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_17.nidm.zip already downloaded at ./input/data/pain/pain_17.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_18.nidm.zip already downloaded at ./input/data/pain/pain_18.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_19.nidm.zip already downloaded at ./input/data/pain/pain_19.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_20.nidm.zip already downloaded at ./input/data/pain/pain_20.nidm.zip\n",
      "http://neurovault.org/collections/1425/pain_21.nidm.zip already downloaded at ./input/data/pain/pain_21.nidm.zip\n"
     ]
    }
   ],
   "source": [
    "request = Request('http://neurovault.org/api/collections/1425/nidm_results/?limit=184&format=json')\n",
    "response = urlopen(request)\n",
    "elevations = response.read()\n",
    "data = json.loads(elevations)\n",
    "\n",
    "pwd = os.path.dirname(os.path.realpath('__file__'))\n",
    "input_dir = os.path.join(pwd, \"input\")\n",
    "data_dir = os.path.join(input_dir, \"data\")\n",
    "pain_dir = os.path.join(data_dir, \"pain\")\n",
    "\n",
    "if not os.path.isdir(pain_dir):\n",
    "    if not os.path.isdir(data_dir):\n",
    "        if not os.path.isdir(input_dir):\n",
    "            os.makedirs(input_dir)\n",
    "        os.makedirs(data_dir)\n",
    "    os.makedirs(pain_dir)\n",
    "\n",
    "for nidm_result in data[\"results\"]:\n",
    "    url = nidm_result[\"zip_file\"]\n",
    "    study_name = nidm_result[\"name\"]\n",
    "    \n",
    "    localzip = os.path.join(pain_dir, study_name + \".zip\")\n",
    "    localzip_rel = localzip.replace(pwd, '.')\n",
    "    if not os.path.isfile(localzip):\n",
    "        # Copy .nidm.zip export locally in a the data directory\n",
    "        try:\n",
    "            f = urlopen(url)\n",
    "            print(\"downloading \" + url + \" at \" + localzip_rel)\n",
    "            with open(localzip, \"wb\") as local_file:\n",
    "                local_file.write(f.read())\n",
    "        except HTTPError, e:\n",
    "            raise Exception([\"HTTP Error:\" + e.code + url])\n",
    "        except URLError, e:\n",
    "            raise Exception([\"URL Error:\" + e.reason + url])\n",
    "    else:\n",
    "        print(url + \" already downloaded at \" + localzip_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/cmaumet/Projects/Data_sharing/dev/nidmresults-paper/input/data/pain/pain_01.nidm.zip']\n",
      "<nidmresults.graph.Graph instance at 0x107410d40>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Graph instance has no attribute 'get_contrast_maps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-26b8b261d1d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnidm_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_contrast_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Graph instance has no attribute 'get_contrast_maps'"
     ]
    }
   ],
   "source": [
    "studies = glob.glob(os.path.join(pain_dir, '*.nidm.zip'))\n",
    "\n",
    "studies = studies[0:1]\n",
    "print(studies)\n",
    "\n",
    "for nidm_file in studies:\n",
    "    g = ni.graph.Graph(nidm_file)\n",
    "    print(g)\n",
    "    print(g.get_contrast_maps())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c9ca6a15afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mSCRIPT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCRIPT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "studies = glob.glob(os.path.join(pain_dir, '*.nidm.zip'))\n",
    "\n",
    "con_maps = dict()\n",
    "varcon_maps = dict()\n",
    "mask_maps = dict()\n",
    "\n",
    "ma_mask_name = os.path.join(out_dir, \"mask_ma\")\n",
    "ma_mask = None\n",
    "\n",
    "\n",
    "\n",
    "studies = studies[0:3]\n",
    "\n",
    "for nidm_file in studies:\n",
    "    study = os.path.basename(nidm_file.replace(\".nidm.zip\", \"\"))\n",
    "    nidm_dir = os.path.join(out_dir, \"pre\", study)\n",
    "    print \"\\nStudy: \" + study\n",
    "\n",
    "    with zipfile.ZipFile(nidm_file) as z:\n",
    "        if not os.path.exists(nidm_dir):\n",
    "            os.makedirs(nidm_dir)\n",
    "        z.extractall(nidm_dir)\n",
    "\n",
    "    nidm_doc = os.path.join(nidm_dir, \"nidm.ttl\")\n",
    "    assert os.path.isfile(nidm_doc)\n",
    "\n",
    "    nidm_graph = Graph()\n",
    "    nidm_graph.parse(nidm_doc, format='turtle')\n",
    "\n",
    "    query = \"\"\"\n",
    "    prefix prov: <http://www.w3.org/ns/prov#>\n",
    "    prefix nidm: <http://purl.org/nidash/nidm#>\n",
    "\n",
    "    prefix contrast_estimation: <http://purl.org/nidash/nidm#NIDM_0000001>\n",
    "    prefix contrast_map: <http://purl.org/nidash/nidm#NIDM_0000002>\n",
    "    prefix stderr_map: <http://purl.org/nidash/nidm#NIDM_0000013>\n",
    "    prefix contrast_name: <http://purl.org/nidash/nidm#NIDM_0000085>\n",
    "    prefix statistic_map: <http://purl.org/nidash/nidm#NIDM_0000076>\n",
    "    prefix mask_map: <http://purl.org/nidash/nidm#NIDM_0000054>\n",
    "\n",
    "    SELECT ?contrastName ?con_file ?std_file\n",
    "    ?mask_file ?software WHERE {\n",
    "     ?con_id a contrast_map: ;\n",
    "          contrast_name: ?contrastName ;\n",
    "          prov:atLocation ?con_file ;\n",
    "          prov:wasGeneratedBy ?con_est .\n",
    "     ?std_id a stderr_map: ;\n",
    "          prov:atLocation ?std_file ;\n",
    "          prov:wasGeneratedBy ?con_est .\n",
    "     ?mask_id a mask_map: ;\n",
    "          prov:atLocation ?mask_file .\n",
    "     ?soft_id a ?software .\n",
    "     ?con_est a contrast_estimation: ;\n",
    "              prov:wasAssociatedWith ?soft_id ;\n",
    "              prov:used ?mask_id .\n",
    "\n",
    "      FILTER(?software NOT IN (\n",
    "        prov:SoftwareAgent, prov:Agent))\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    sd = nidm_graph.query(query)\n",
    "\n",
    "    if sd:\n",
    "        for row in sd:\n",
    "            con_name, con_file, std_file, mask_file, software = row\n",
    "            con_file = os.path.join(nidm_dir, con_file)\n",
    "            std_file = os.path.join(nidm_dir, std_file)\n",
    "            mask_file = os.path.join(nidm_dir, mask_file)\n",
    "\n",
    "            if str(con_name) == \"pain\":\n",
    "                if software == URIRef(SCR_SPM.uri):\n",
    "                    print \"--> analyzed with SPM\"\n",
    "                    # If study was performed with SPM, reslice to FSL's\n",
    "                    # template space\n",
    "                    for to_reslice in [con_file, std_file, mask_file]:\n",
    "                        file_name = os.path.basename(\n",
    "                            to_reslice).split(\".\")[0]\n",
    "                        resliced_file = os.path.join(\n",
    "                            out_dir, study + \"_\" + file_name + \"_r\")\n",
    "                        cmd = [\n",
    "                            \"cd \\\"\" + nidm_dir + \"\\\";\" +\n",
    "                            \" flirt -in \" + file_name + \" -ref \" +\n",
    "                            \"$FSLDIR/data/standard/MNI152_T1_2mm \" +\n",
    "                            \"-applyxfm -usesqform \" +\n",
    "                            \"-out \" + resliced_file\n",
    "                            ]\n",
    "                        print \"Running \" + \",\".join(cmd)\n",
    "                        check_call(cmd, shell=True)\n",
    "\n",
    "                        if to_reslice == mask_file:\n",
    "                            mask_file = resliced_file\n",
    "                        elif to_reslice == con_file:\n",
    "                            con_maps[study] = resliced_file\n",
    "                        elif to_reslice == std_file:\n",
    "                            std_file = resliced_file\n",
    "\n",
    "                elif software == URIRef(SCR_FSL.uri):\n",
    "                    print \"--> analyzed with FSL\"\n",
    "                    # If study was performed with FSL, rescale to a target\n",
    "                    # value of 100\n",
    "                    for to_rescale in [con_file, std_file]:\n",
    "                        file_name = os.path.basename(\n",
    "                            to_rescale).split(\".\")[0]\n",
    "                        rescaled_file = os.path.join(\n",
    "                            out_dir, study + \"_\" + file_name + \"_s\")\n",
    "                        cmd = [\n",
    "                            \"cd \\\"\" + nidm_dir + \"\\\";\" +\n",
    "                            \" fslmaths \\\"\" + file_name + \"\\\" -div 100 \" +\n",
    "                            \" \\\"\" + rescaled_file + \"\\\"\"\n",
    "                            ]\n",
    "                        print \"Running \" + \",\".join(cmd)\n",
    "                        check_call(cmd, shell=True)\n",
    "\n",
    "                        if to_rescale == con_file:\n",
    "                            con_maps[study] = \"\\\"\" + rescaled_file + \"\\\"\"\n",
    "                        elif to_rescale == std_file:\n",
    "                            std_file = \"\\\"\" + rescaled_file + \"\\\"\"\n",
    "\n",
    "                    mask_file = mask_file.replace(\"file://.\", nidm_dir)\n",
    "\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                        'Unknown neuroimaging software: ' + str(software))\n",
    "\n",
    "                # Create varcope from standard error map\n",
    "                varcope_file = \"\\\"\" + \\\n",
    "                               os.path.join(out_dir, study + \"_varcope\") +\\\n",
    "                               \"\\\"\"\n",
    "                cmd = [\" fslmaths \" + std_file + \" -sqr \" + varcope_file]\n",
    "                print \"Running \" + \",\".join(cmd)\n",
    "                check_call(cmd, shell=True)\n",
    "\n",
    "                varcon_maps[study] = varcope_file\n",
    "\n",
    "                # Compute meta-analysis mask as the intersection of all\n",
    "                # study analysis masks\n",
    "                if ma_mask is None:\n",
    "                    ma_mask = mask_file\n",
    "                else:\n",
    "                    cmd = [\n",
    "                        \" fslmaths \\\"\" + mask_file + \"\\\" -min \" +\n",
    "                        \"\\\"\" + ma_mask + \"\\\" \\\"\" + ma_mask_name + \"\\\"\"\n",
    "                        ]\n",
    "                    print \"Running \" + \",\".join(cmd)\n",
    "                    check_call(cmd, shell=True)\n",
    "                    ma_mask = ma_mask_name\n",
    "            else:\n",
    "                print \"Ignore contrast '\" + str(con_name) + \"'.\"\n",
    "\n",
    "    else:\n",
    "        print \"Query returned no results for study \"+study+\".\"\n",
    "\n",
    "# Binarize the analysis mask\n",
    "cmd = [\"fslmaths \\\"\" + ma_mask + \"\\\" -thr 0.9 -bin \\\"\" + ma_mask + \"\\\"\"]\n",
    "print \"Running \" + \",\".join(cmd)\n",
    "check_call(cmd, shell=True)\n",
    "\n",
    "# Sort copes and varcopes by study names\n",
    "to_merge = {'copes': collections.OrderedDict(sorted(con_maps.items())),\n",
    "            'varcopes': collections.OrderedDict(\n",
    "                sorted(varcon_maps.items()))}\n",
    "for file_name, files in to_merge.items():\n",
    "    cmd = [\n",
    "        \"fslmerge -t \\\"\"+os.path.join(out_dir, file_name) +\n",
    "        \".nii.gz\\\" \"+\" \".join(files.values())\n",
    "    ]\n",
    "    print \"Running \" + \",\".join(cmd)\n",
    "    check_call(cmd, shell=True)\n",
    "\n",
    "# Remove NaNs from copes and varcopes\n",
    "# (SPM code background with NaNs while FSL uses zeros)\n",
    "cmd = [\"cd \" + out_dir + \"; fslmaths copes.nii.gz -nan copes\"]\n",
    "print \"Running \" + \",\".join(cmd)\n",
    "check_call(cmd, shell=True)\n",
    "\n",
    "cmd = [\"cd \" + out_dir + \"; fslmaths varcopes.nii.gz -nan varcopes\"]\n",
    "print \"Running \" + \",\".join(cmd)\n",
    "check_call(cmd, shell=True)\n",
    "\n",
    "# Mixed-effects GLM (study-level)\n",
    "cmd = [\n",
    "    \"cd \" + out_dir + \"; flameo --cope=copes --vc=varcopes --ld=stats \"\n",
    "    \" --dm=\" + os.path.join(FSL_DESIGN_DIR, \"simple_meta_analysis.mat\") +\n",
    "    \" --cs=\" + os.path.join(FSL_DESIGN_DIR, \"simple_meta_analysis.grp\") +\n",
    "    \" --tc=\" + os.path.join(FSL_DESIGN_DIR, \"simple_meta_analysis.con \") +\n",
    "    \" --mask=\\\"\"+ma_mask_name+\"\\\" --runmode=flame1\"]\n",
    "print \"Running \" + \",\".join(cmd)\n",
    "check_call(cmd, shell=True)\n",
    "\n",
    "stat_dir = os.path.join(out_dir, \"stats\")\n",
    "\n",
    "# FWE Voxel-wise corrected threshold p<0.05 (with a cluster forming\n",
    "# threshold of p<0.001 uncorrected)\n",
    "# Scripts from http://blogs.warwick.ac.uk/nichols/entry/flame_without_1st/\n",
    "cmd = [\n",
    "    \"cd \" + out_dir + \"; \" +\n",
    "    \"echo $($FSLDIR/bin/fslnvols copes) - 1 | bc -l  > stats/dof ;\" +\n",
    "    \"/bin/rm -f stats/zem* stats/zols* stats/mask* ;\" +\n",
    "    \"$FSLDIR/bin/smoothest -d $(cat stats/dof) -m \" + ma_mask_name +\n",
    "    \" -r stats/res4d > stats/smoothness ;\" +\n",
    "    \"awk '/VOLUME/ {print $2}' stats/smoothness > thresh_zstat1.vol ;\" +\n",
    "    \"awk '/DLH/ {print $2}' stats/smoothness > thresh_zstat1.dlh ;\" +\n",
    "    \"$FSLDIR/bin/fslmaths stats/zstat1 -mas \" + ma_mask_name +\n",
    "    \" thresh_zstat1;\" +\n",
    "    \"$FSLDIR/bin/cluster -i thresh_zstat1 -c stats/cope1 -t 3.1 -p 0.05\" +\n",
    "    \" -d $(cat thresh_zstat1.dlh) --volume=$(cat thresh_zstat1.vol) \" +\n",
    "    \"--othresh=thresh_zstat1 -o cluster_mask_zstat1 --connectivity=26 \" +\n",
    "    \"--mm --olmax=lmax_zstat1_tal.txt > cluster_zstat1_std.txt;\" +\n",
    "    \"$FSLDIR/bin/cluster2html . cluster_zstat1 -std;\" +\n",
    "    \"MinMax=$($FSLDIR/bin/fslstats thresh_zstat1 -l 0.0001 -R);\" +\n",
    "    \"$FSLDIR/bin/overlay 1 0 $FSLDIR/data/standard/MNI152_T1_2mm.nii.gz \" +\n",
    "    \"-a thresh_zstat1 $MinMax \" +\n",
    "    \"rendered_thresh_zstat1;\" +\n",
    "    \"$FSLDIR/bin/slicer rendered_thresh_zstat1 -S 2 750 \" +\n",
    "    \"rendered_thresh_zstat1.png;\" +\n",
    "    \"cp $FSLDIR/etc/luts/ramp.gif .ramp.gif\"\n",
    "]\n",
    "print \"Running \" + \",\".join(cmd)\n",
    "check_call(cmd, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
